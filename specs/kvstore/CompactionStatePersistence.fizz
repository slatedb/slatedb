---
deadlock_detection: false
options:
    max_actions: 30
    crash_on_yield: false
action_options:
    Compactor.StartUp:
        max_actions: 4
    Compactor.InitiateCompaction:
        max_actions: 2
    Compactor.CompactionProgress:
        max_actions: 2
    Compactor.CompleteCompaction:
        max_actions: 2
    Compactor.RetryManifestWrite:
        max_actions: 1

---

# Model the updated compaction state persistence algorithm with epoch-based fencing
# Based on RFC 0012 updated protocol

COMPACTOR_IDS = ["compactor_A", "compactor_B"]
L0_SSTS = ["sst1", "sst2"]
SORTED_RUNS = ["sr1", "sr2"]

CompactionState = enum('Scheduled', 'InProgress', 'Completed', 'Failed')
FencingResult = enum('SUCCESS', 'FENCED', 'VERSION_CONFLICT', 'PANIC')

role Compactor:
    action Init:
        self.id = ""
        self.local_epoch = 0
        self.is_active = False
        self.fenced = False
        self.compaction_jobs = {}
        self.dirty_manifest_state = {}
        
    atomic action StartUp:
        require not self.is_active and not self.fenced
        compactor_id = any COMPACTOR_IDS
        self.id = compactor_id
        
        # Step 1: T=1 - Fetch latest manifest file (00005.manifest)
        latest_manifest = object_store.get_latest_manifest()
        
        # Step 2: T=2 - Fetch latest compactor file (00005.compactor)
        latest_compactor_state = object_store.get_latest_compactor_state()
        
        # Step 3: T=3 - Build dirty compactionState by merging L0 SSTs and SortedRuns
        # Copy SortedRuns from .compactor file to compactionState
        # Add and delete L0 SSTs of .manifest in compactionState
        merged_state = {
            "l0_ssts": list(latest_manifest["l0_ssts"]),  
            "sorted_runs": list(latest_compactor_state["sorted_runs"]),
            "compactor_epoch": latest_compactor_state["compactor_epoch"]
        }
        
        # Step 4: T=4 - Increment compactor_epoch and write to next sequential .compactor file
        new_epoch = latest_compactor_state["compactor_epoch"] + 1
        self.local_epoch = new_epoch
        
        # Write compaction job to next .compactor file (00006.compactor)
        # Two level validation as per RFC with retry logic
        result = object_store.cas_write_compactor_state_with_retry(merged_state, new_epoch, self.id)
        
        if result == FencingResult.SUCCESS:
            # Before marking self as active, fence any compactors with lower epochs
            for compactor in [compactor_A, compactor_B]:
                if compactor != self and compactor.is_active and compactor.local_epoch < self.local_epoch:
                    compactor.fenced = True
                    compactor.is_active = False
                    _active_compactors[compactor.id] = None
            
            self.is_active = True
            _active_compactors[self.id] = self.local_epoch
            self.dirty_manifest_state = merged_state
        elif result == FencingResult.FENCED:
            self.fenced = True
        # VERSION_CONFLICT and PANIC cases are handled internally by the retry function
            
    atomic action InitiateCompaction:
        require self.is_active and not self.fenced
        
        # Create a compaction job
        job_id = self.id + "_job_" + str(len(self.compaction_jobs))
        sources = any [L0_SSTS[:1], L0_SSTS[:2]]
        destination = any SORTED_RUNS
        
        compaction_job = {
            "id": job_id,
            "sources": sources,
            "destination": destination,
            "state": CompactionState.Scheduled,
            "progress_ssts": []  # Track SSTs added during progress
        }
        
        # Write compaction job to next .compactor file (00007.compactor)
        result = object_store.write_compaction_job(compaction_job, self.local_epoch, self.id)
        
        if result == FencingResult.SUCCESS:
            self.compaction_jobs[job_id] = compaction_job
            # Transition job to InProgress state for execution
            self.compaction_jobs[job_id]["state"] = CompactionState.InProgress
        elif result == FencingResult.FENCED:
            self.fenced = True
            self.is_active = False
            _active_compactors[self.id] = None
        elif result == FencingResult.PANIC:
            self.panicked = True
            self.is_active = False
            _active_compactors[self.id] = None
            
    atomic action CompactionProgress:
        require self.is_active and not self.fenced
        
        # Find an InProgress job to update
        in_progress_jobs = []
        for jid in self.compaction_jobs:
            job = self.compaction_jobs[jid]
            if job["state"] == CompactionState.InProgress:
                in_progress_jobs.append(jid)
        
        if len(in_progress_jobs) == 0:
            return
            
        job_id = any in_progress_jobs
        job = self.compaction_jobs[job_id]
        
        # Simulate progress: add an SST to the sorted run being built
        new_sst_name = job["destination"] + "_part_" + str(len(job["progress_ssts"]))
        job["progress_ssts"].append(new_sst_name)
        
        # Write compactionState with latest progress to next .compactor file (00008.compactor)
        result = object_store.write_compaction_progress(job, self.local_epoch, self.id)
        
        if result == FencingResult.FENCED:
            self.fenced = True
            self.is_active = False
            _active_compactors[self.id] = None
        elif result == FencingResult.SUCCESS:
            # Progress update successful, continue compaction
            pass
                
    atomic action CompleteCompaction:
        require self.is_active and not self.fenced and len(self.compaction_jobs) > 0
        
        # Pick an InProgress job to complete
        in_progress_jobs = []
        for jid in self.compaction_jobs:
            job = self.compaction_jobs[jid]
            if job["state"] == CompactionState.InProgress:
                in_progress_jobs.append(jid)
        
        if len(in_progress_jobs) == 0:
            return
            
        job_id = any in_progress_jobs
        job = self.compaction_jobs[job_id]
        job["state"] = CompactionState.Completed
        
        # Step 1: Write compactor state with completed job to next .compactor file (00009.compactor)
        result1 = object_store.write_compactor_state_with_job(job, self.local_epoch, self.id)
        if result1 == FencingResult.FENCED:
            self.fenced = True
            self.is_active = False
            _active_compactors[self.id] = None
            return
            
        # Step 2: Update in-memory manifest state to reflect latest SRs/SSTs
        # Remove old SSTs/SRs that were compacted, add new SR
        new_l0_ssts = []
        for sst in self.dirty_manifest_state["l0_ssts"]:
            if sst not in job["sources"]:
                new_l0_ssts.append(sst)
        
        self.dirty_manifest_state = {
            "l0_ssts": new_l0_ssts,
            "sorted_runs": self.dirty_manifest_state["sorted_runs"] + [job["destination"]]
        }
        
        # Step 3: Write in-memory manifest state to next sequential .manifest file
        result2 = object_store.cas_write_manifest(self.dirty_manifest_state, self.local_epoch, self.id)
        if result2 == FencingResult.VERSION_CONFLICT:
            # Trigger retry logic (Step 8 in RFC)
            pass  # Will be handled by RetryManifestWrite action
        elif result2 == FencingResult.SUCCESS:
            # Successfully completed compaction
            pass
            
    atomic action RetryManifestWrite:
        require self.is_active and not self.fenced
        
        # Step 8: On file version exists error, fetch both latest files
        latest_compactor_state = object_store.get_latest_compactor_state()
        latest_manifest = object_store.get_latest_manifest()
        
        # Check the compactor_epoch and fence if necessary
        if latest_compactor_state["compactor_epoch"] > self.local_epoch:
            # Compactor is stale and fenced
            self.fenced = True
            self.is_active = False
            _active_compactors[self.id] = None
            return
        elif latest_compactor_state["compactor_epoch"] < self.local_epoch:
            # Active compactor has updated .compactor file, retry manifest write
            pass
        
        # Epochs match, retry manifest write
        result = object_store.cas_write_manifest(self.dirty_manifest_state, self.local_epoch, self.id)
        if result == FencingResult.FENCED:
            self.fenced = True
            self.is_active = False
            _active_compactors[self.id] = None
            


role ObjectStore:
    action Init:
        self.manifest_files = {}
        self.compactor_files = {}
        self.manifest_id = 5  # Start at 00005 as per RFC example
        self.compactor_id = 5  # Start at 00005 as per RFC example
        self.current_manifest = {
            "id": 5,
            "l0_ssts": list(L0_SSTS), 
            "sorted_runs": [],
            "writer_epoch": 1
        }
        self.current_compactor_state = {
            "id": 5,
            "compactor_epoch": 0,
            "sorted_runs": [],
            "active_compactions": {}
        }
        
    atomic func get_latest_manifest():
        return self.current_manifest
        
    atomic func get_latest_compactor_state():
        return self.current_compactor_state
        
    atomic func cas_write_compactor_state(state, epoch, compactor_id):
        # Two level validation as per updated RFC
        
        # Level 1: Epoch Check - Only allow exact match for startup
        if epoch != self.current_compactor_state["compactor_epoch"] + 1:
            return FencingResult.FENCED
            
        # Level 2: File version check (CAS) - next sequential position
        next_id = self.compactor_id + 1
        if next_id in self.compactor_files:
            existing_file = self.compactor_files[next_id]
            existing_epoch = existing_file["compactor_epoch"]
            
            if existing_epoch > epoch:
                return FencingResult.FENCED  # Higher epoch exists
            elif existing_epoch == epoch:
                return FencingResult.FENCED  # Same epoch = illegal state  
            elif existing_epoch < epoch:
                return FencingResult.VERSION_CONFLICT  # Retry with next file ID
                
        # Success case - new compactor takes over
        new_state = dict(state)
        new_state["id"] = next_id
        new_state["compactor_epoch"] = epoch
        new_state["owner"] = compactor_id
        if "active_compactions" not in new_state:
            new_state["active_compactions"] = {}
        
        self.compactor_files[next_id] = new_state
        self.current_compactor_state = new_state
        self.compactor_id = next_id
        
        return FencingResult.SUCCESS
        
    atomic func cas_write_compactor_state_with_retry(state, epoch, compactor_id):
        # RFC: If latest .compactor compactor_epoch < current compactor's epoch, 
        # increment the .compactor file ID by 1 and retry until successful
        
        # Level 1: Epoch Check - Only allow exact match for startup
        if epoch != self.current_compactor_state["compactor_epoch"] + 1:
            return FencingResult.FENCED
            
        # Level 2: File version check with retry logic
        retry_file_id = self.compactor_id + 1
        max_retries = 2  # Prevent infinite loops in model checking
        retries = 0
        
        while retries < max_retries:
            if retry_file_id not in self.compactor_files:
                # File doesn't exist, we can write here
                new_state = dict(state)
                new_state["id"] = retry_file_id
                new_state["compactor_epoch"] = epoch
                new_state["owner"] = compactor_id
                if "active_compactions" not in new_state:
                    new_state["active_compactions"] = {}
                
                self.compactor_files[retry_file_id] = new_state
                self.current_compactor_state = new_state
                self.compactor_id = retry_file_id
                return FencingResult.SUCCESS
                
            # File exists, check epoch
            existing_file = self.compactor_files[retry_file_id]
            existing_epoch = existing_file["compactor_epoch"]
            
            if existing_epoch > epoch:
                return FencingResult.FENCED  # Higher epoch exists
            elif existing_epoch == epoch:
                return FencingResult.FENCED  # Same epoch = illegal state
            elif existing_epoch < epoch:
                # RFC: increment file ID and retry
                retry_file_id = retry_file_id + 1
                retries = retries + 1
                continue
                
        # Max retries exceeded
        return FencingResult.FENCED
        
    atomic func write_compaction_job(job, epoch, compactor_id):
        # Check if compactor is still valid
        if epoch != self.current_compactor_state["compactor_epoch"]:
            return FencingResult.FENCED
            
        next_id = self.compactor_id + 1
        if next_id in self.compactor_files:
            return FencingResult.FENCED  # File exists, compactor is fenced
            
        new_state = dict(self.current_compactor_state)
        new_state["id"] = next_id
        if "active_compactions" not in new_state:
            new_state["active_compactions"] = {}
        new_state["active_compactions"][job["id"]] = job
        
        self.compactor_files[next_id] = new_state
        self.current_compactor_state = new_state
        self.compactor_id = next_id
        
        return FencingResult.SUCCESS
        
    atomic func write_compaction_progress(job, epoch, compactor_id):
        # Check if compactor is still valid
        if epoch != self.current_compactor_state["compactor_epoch"]:
            return FencingResult.FENCED
            
        next_id = self.compactor_id + 1
        if next_id in self.compactor_files:
            return FencingResult.FENCED  # File exists, compactor is fenced
            
        new_state = dict(self.current_compactor_state)
        new_state["id"] = next_id
        if "active_compactions" not in new_state:
            new_state["active_compactions"] = {}
        new_state["active_compactions"][job["id"]] = job
        
        self.compactor_files[next_id] = new_state
        self.current_compactor_state = new_state
        self.compactor_id = next_id
        
        return FencingResult.SUCCESS
        
    atomic func write_compactor_state_with_job(job, epoch, compactor_id):
        if epoch != self.current_compactor_state["compactor_epoch"]:
            return FencingResult.FENCED
            
        next_id = self.compactor_id + 1
        if next_id in self.compactor_files:
            return FencingResult.FENCED
            
        new_state = dict(self.current_compactor_state)
        new_state["id"] = next_id
        if "active_compactions" not in new_state:
            new_state["active_compactions"] = {}
        new_state["active_compactions"][job["id"]] = job
        
        self.compactor_files[next_id] = new_state
        self.current_compactor_state = new_state
        self.compactor_id = next_id
        
        return FencingResult.SUCCESS
        
    atomic func cas_write_manifest(manifest_state, epoch, compactor_id):
        # Check if compactor is still valid
        if epoch != self.current_compactor_state["compactor_epoch"]:
            return FencingResult.FENCED
            
        next_id = self.manifest_id + 1
        if next_id in self.manifest_files:
            return FencingResult.VERSION_CONFLICT  # Triggers retry logic
            
        new_manifest = dict(manifest_state)
        new_manifest["id"] = next_id
        new_manifest["compactor_epoch"] = epoch
        
        self.manifest_files[next_id] = new_manifest
        self.current_manifest = new_manifest  
        self.manifest_id = next_id
        
        return FencingResult.SUCCESS

action Init:
    # Initialize multiple compactors as per RFC naming
    compactor_A = Compactor()
    compactor_B = Compactor()
    
    object_store = ObjectStore()
    
    # Track active compactors for assertions
    _active_compactors = {}

# Safety Properties

always assertion SingleActiveCompactor:
    """Only one compactor should be active at any time (mutual exclusion)"""
    active_count = 0
    for compactor_id in _active_compactors:
        if _active_compactors[compactor_id] != None:
            active_count = active_count + 1
    return active_count <= 1

always assertion EpochMonotonicity:
    """Compactor epochs should be monotonically increasing"""
    return object_store.current_compactor_state["compactor_epoch"] >= 0

always assertion FencedCompactorsStayInactive:
    """Once a compactor is fenced, it should remain inactive"""
    fenced_active = False
    for compactor in [compactor_A, compactor_B]:
        if compactor.fenced and compactor.is_active:
            fenced_active = True
            break
    return not fenced_active

always assertion ValidEpochOwnership:
    """Active compactor should own the current epoch"""
    active_count = 0
    for compactor_id in _active_compactors:
        if _active_compactors[compactor_id] != None:
            active_count = active_count + 1
            if _active_compactors[compactor_id] != object_store.current_compactor_state["compactor_epoch"]:
                return False
    return True

always assertion CompactionJobStateConsistency:
    """Compaction jobs should follow proper state transitions"""
    for compactor in [compactor_A, compactor_B]:
        for job_id in compactor.compaction_jobs:
            job = compactor.compaction_jobs[job_id]
            # Jobs should have valid states
            valid_states = [CompactionState.Scheduled, CompactionState.InProgress, CompactionState.Completed, CompactionState.Failed]
            if job["state"] not in valid_states:
                return False
            # Jobs should have required fields
            if "sources" not in job or "destination" not in job or "progress_ssts" not in job:
                return False
            # Progress SSTs should be a list (checking type)
            if type(job["progress_ssts"]) != type([]):
                return False
    return True

# Liveness Properties  

always eventually assertion CompactorEventuallyActive:
    """Eventually, one compactor should become active (progress guarantee)"""
    active_count = 0
    for compactor_id in _active_compactors:
        if _active_compactors[compactor_id] != None:
            active_count = active_count + 1
    return active_count >= 1

always eventually assertion CompactionJobsComplete:
    """Compaction jobs should eventually complete (no starvation)"""
    incomplete_jobs = False
    for compactor in [compactor_A, compactor_B]:
        if compactor.is_active:
            for job_id in compactor.compaction_jobs:
                job = compactor.compaction_jobs[job_id]
                if job["state"] == CompactionState.InProgress or job["state"] == CompactionState.Scheduled:
                    incomplete_jobs = True
                    break
    return not incomplete_jobs

always eventually assertion SystemMakesProgress:
    """System should eventually process compactions and update manifest"""
    # Either no jobs exist, or manifest has been updated from initial state
    jobs_exist = False
    for compactor in [compactor_A, compactor_B]:
        if len(compactor.compaction_jobs) > 0:
            jobs_exist = True
            break
    
    if not jobs_exist:
        return True  # No jobs, so progress not needed
        
    # If jobs exist, manifest should have changed from initial state
    return object_store.current_manifest["id"] > 5

always eventually assertion ProgressUpdatesEventuallyOccur:
    """InProgress compaction jobs should eventually make progress"""
    stuck_jobs = False
    for compactor in [compactor_A, compactor_B]:
        if compactor.is_active:
            for job_id in compactor.compaction_jobs:
                job = compactor.compaction_jobs[job_id]
                if job["state"] == CompactionState.InProgress and len(job["progress_ssts"]) == 0:
                    stuck_jobs = True
                    break
    return not stuck_jobs 