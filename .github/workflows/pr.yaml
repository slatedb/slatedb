name: PR Checks

on:
  push:
    branches:
      - main
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]

# Make sure CI fails on all warnings, including Clippy lints
env:
  RUSTFLAGS: "-Dwarnings"

permissions:
  # Required for PR comments
  pull-requests: write
  # Required for storing benchmark results
  contents: write

jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: cargo install cargo-hack
        run: cargo +stable install cargo-hack --locked
      - name: cargo check
        run: cargo hack check --each-feature --no-dev-deps

  clippy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: cargo install cargo-hack
        run: cargo +stable install cargo-hack --locked
      - name: cargo clippy
        run: cargo hack clippy --each-feature --no-dev-deps && cargo hack clippy --lib -p slatedb --tests

  style:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: cargo fmt
        run: cargo fmt -- --check

  flatbuffers:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # Install specific version of flatc (24.3.25)
      - name: Install flatc
        run: |
          wget https://github.com/google/flatbuffers/releases/download/v24.3.25/Linux.flatc.binary.g++-13.zip
          unzip Linux.flatc.binary.g++-13.zip
          sudo mv flatc /usr/local/bin/

      # Check for differences
      - name: Generate and validate files
        run: |
          flatc -o tmp/generated --rust --gen-all schemas/manifest.fbs
          if ! diff -r src/generated/*.rs tmp/generated; then
            echo "Generated files do not match!"
            exit 1
          fi

  tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: taiki-e/install-action@v2
        with:
          tool: nextest@0.9.84
      - name: Run Tests
        run: cargo nextest run --all-features --profile ci

  microbenchmarks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run benchmark
        # Hardcode microbenchmarks because `libtest` runs otherwise. See:
        # https://bheisler.github.io/criterion.rs/book/faq.html
        run: cargo bench --bench db_operations -- --output-format bencher | tee output.txt

      - name: Download nightly benchmark data
        uses: actions/cache@v4
        with:
          path: ./microbenchmarks-cache
          key: ${{ runner.os }}-benchmark

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: cargo bench --bench db_operations
          tool: 'cargo'
          output-file-path: output.txt
          github-token: ${{ secrets.GITHUB_TOKEN }}
          external-data-json-path: ./microbenchmarks-cache/benchmark-data.json
          comment-on-alert: true
          summary-always: true
          max-items-in-chart: 30
