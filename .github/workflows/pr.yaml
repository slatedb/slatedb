name: PR Checks

on:
  push:
    branches:
      - main
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]

# Make sure CI fails on all warnings, including Clippy lints
env:
  RUSTFLAGS: "-Dwarnings"

permissions:
  # Required for PR comments
  pull-requests: write
  # Required for storing benchmark results
  contents: write

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: cargo install cargo-hack
        run: cargo +stable install cargo-hack --locked
      - name: cargo check
        run: cargo hack check --each-feature --no-dev-deps --workspace

  clippy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: cargo install cargo-hack
        run: cargo +stable install cargo-hack --locked
      - name: cargo clippy
        run: |
          cargo hack clippy --each-feature --no-dev-deps --workspace &&
          cargo hack clippy --workspace --tests

  style:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: cargo fmt
        run: cargo fmt -- --check

  typos:
    runs-on: ubuntu-latest
    name: typos
    steps:
      - uses: actions/checkout@v4
      - name: Check spelling
        uses: crate-ci/typos@v1
        with:
          files: |
            rfcs
            website

  flatbuffers:
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4
        with:
          # Allow script to fetch base ref/commits if needed
          fetch-depth: 0

      # Install specific version of flatc (24.3.25)
      - name: Install flatc
        run: |
          wget https://github.com/google/flatbuffers/releases/download/v24.3.25/Linux.flatc.binary.g++-13.zip
          unzip Linux.flatc.binary.g++-13.zip
          sudo mv flatc /usr/local/bin/

      # Check schema evolution rules against the base revision
      - name: Check FlatBuffers evolution
        run: bash scripts/check_flatbuffers_evolution.sh

      # Check for differences
      - name: Generate and validate files
        run: |
          flatc -o tmp/generated --rust --gen-all schemas/root.fbs
          # Validate only files produced by root.fbs in this step.
          # The checked-in generated folder may also contain outputs from other schemas
          # (e.g., manifest_generated.rs) and docs (README.md). Those are unrelated to
          # this invocation of flatc and would show up as "extra files" in a recursive
          # dir-to-dir diff even when root.fbs outputs match. Exclude them to avoid
          # false positives.
          if ! diff -r -x 'README.md' -x 'manifest_generated.rs' slatedb/src/generated tmp/generated; then
            echo "Generated files do not match!"
            exit 1
          fi

  tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: taiki-e/install-action@v2
        with:
          tool: nextest@0.9.98
      - name: Install gdb
        run: |
          sudo apt-get update
          sudo apt-get install -y gdb
      - name: Run Tests
        run: cargo nextest run --workspace --all-features --profile ci
      - name: Run Doc Tests
        run: cargo test --doc --all-features
      - name: Run DST Tests
        run: cargo nextest run -p slatedb-dst --all-features --profile dst
        env:
          RUSTFLAGS: "--cfg dst --cfg tokio_unstable"

  tests-cross:
    name: tests (cross)
    needs: tests
    strategy:
      fail-fast: false
      matrix:
        os: [macos-latest, windows-latest]
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
      - uses: taiki-e/install-action@v2
        with:
          tool: nextest@0.9.98
      - name: Run Tests
        run: cargo nextest run --workspace --all-features
      - name: Run Doc Tests
        run: cargo test --doc --all-features

  bindings-python:
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install maturin
        run: pip install maturin

      - name: Build and install package with test dependencies
        working-directory: ./slatedb-py
        run: |
          python -m venv .venv
          source .venv/bin/activate
          maturin develop
          pip install -e .[test]

      - name: Install lint dependencies (Ruff)
        working-directory: ./slatedb-py
        run: |
          source .venv/bin/activate
          pip install -e .[lint]

      - name: Run Ruff linter
        working-directory: ./slatedb-py
        run: |
          source .venv/bin/activate
          ruff check . --output-format=github

      - name: Run Python tests
        working-directory: ./slatedb-py
        run: |
          source .venv/bin/activate
          pytest -xvs

  bindings-go:
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4

      - name: Set up Go 1.24.x
        uses: actions/setup-go@v5
        with:
          go-version: '1.24.x'

      - name: Install build dependencies for CGO
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential pkg-config

      - name: Build Rust FFI library for Go bindings
        run: cargo build --release -p slatedb-go

      - name: Run Go tests (slatedb-go)
        working-directory: ./slatedb-go/go
        env:
          CGO_ENABLED: '1'
          CGO_LDFLAGS: "-L${{ github.workspace }}/target/release"
          LD_LIBRARY_PATH: "${{ github.workspace }}/target/release:${LD_LIBRARY_PATH}"
        run: go test -v ./...

  microbenchmarks:
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4

      - name: Run benchmark
        run: cargo bench -- --output-format bencher | tee output.txt

      - name: Download nightly benchmark data
        uses: actions/cache/restore@v4
        with:
          path: ./microbenchmarks-cache
          key: ${{ runner.os }}-microbenchmarks

      - name: Update benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: cargo bench
          tool: 'cargo'
          output-file-path: output.txt
          github-token: ${{ secrets.GITHUB_TOKEN }}
          external-data-json-path: ./microbenchmarks-cache/benchmark-data.json
          comment-on-alert: true
          summary-always: true
          max-items-in-chart: 30

  test_website:
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - uses: actions/checkout@v4
      - name: Get changed files
        id: changed-website-files
        uses: tj-actions/changed-files@6cb76d07bee4c9772c6882c06c37837bf82a04d3 # v46
        with:
          files: website/**

      - name: Build website
        shell: bash
        if: steps.changed-website-files.outputs.any_changed == 'true'
        working-directory: ./website
        run: |
          npm install
          npm run build

  chaos:
    name: Chaos tests
    runs-on: ubuntu-latest
    timeout-minutes: 25
    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl
          sudo snap install aws-cli --classic

      - name: Create docker network
        run: docker network create chaos-net

      - name: Start MinIO
        run: |
          docker run -d --name minio --network chaos-net \
            -p 9000:9000 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio server /data --console-address :9001
          # Wait for readiness
          for i in {1..60}; do
            if curl -sf http://127.0.0.1:9000/minio/health/ready >/dev/null; then echo ready; break; fi; sleep 1; done

      - name: Start mikkmokk-proxy (baseline)
        run: |
          # Start with no HTTP faults; Toxiproxy handles TCP faults
          docker run -d --name mikkmokk --network chaos-net \
            -e DESTINATION_URL=http://minio:9000 \
            -e PROXY_BIND=0.0.0.0 \
            -e PROXY_PORT=8080 \
            -e ADMIN_BIND=0.0.0.0 \
            -e ADMIN_PORT=7070 \
            -p 8080:8080 -p 7070:7070 \
            docker.io/ivarref/mikkmokk-proxy:v0.1.63

      - name: Start Toxiproxy
        run: |
          docker run -d --name toxiproxy --network chaos-net \
            -p 8474:8474 -p 9001:9001 \
            ghcr.io/shopify/toxiproxy:latest
          # Wait for API
          for i in {1..60}; do
            if curl -sf http://127.0.0.1:8474/proxies >/dev/null; then echo ready; break; fi; sleep 1; done

      - name: Create S3 bucket (through proxy)
        env:
          AWS_ACCESS_KEY_ID: minioadmin
          AWS_SECRET_ACCESS_KEY: minioadmin
          AWS_REGION: us-east-1
        run: |
          # Create s3 toxiproxy if not exist (TCP-level path only)
          curl -sf -X POST http://127.0.0.1:8474/proxies \
            -H 'Content-Type: application/json' \
            -d '{"name":"s3","listen":"0.0.0.0:9001","upstream":"minio:9000"}' || true
          # Create bucket via the proxied endpoint
          aws --endpoint-url http://127.0.0.1:9001 s3api create-bucket --bucket slatedb-test || true

      - name: Run chaos scenarios
        id: chaos
        env:
          SLATEDB_TEST_NUM_WRITERS: "12"
          SLATEDB_TEST_NUM_READERS: "4"
          SLATEDB_TEST_WRITES_PER_TASK: "500"
          SLATEDB_TEST_KEY_LENGTH: "256"
        run: |
          chmod +x scripts/run_chaos_scenarios.sh
          if scripts/run_chaos_scenarios.sh; then
            echo "ok=true" >> $GITHUB_OUTPUT
          else
            echo "ok=false" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Summarize results
        if: always()
        run: |
          echo "## ðŸŒªï¸ SlateDB Toxiproxy Chaos" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.chaos.outputs.ok }}" = "true" ]; then
            echo "All scenarios passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "One or more scenarios failed" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Dump logs on failure
        if: failure()
        run: |
          echo "--- MinIO logs ---"; docker logs --tail 500 minio || true
          echo "--- mikkmokk logs ---"; docker logs --tail 500 mikkmokk || true
          echo "--- Toxiproxy logs ---"; docker logs --tail 500 toxiproxy || true
          echo "--- Toxiproxy proxies ---"; curl -sf http://127.0.0.1:8474/proxies || true
