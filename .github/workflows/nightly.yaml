name: Nightly Benchmarks

on:
  schedule:
    # Run at midnight Pacific (8 AM UTC)
    - cron: '0 8 * * *'
  workflow_dispatch:  # Allow manual trigger

permissions:
  # Required for storing benchmark results
  contents: write

jobs:
  # Run and save nightly microbenchmark data so PRs have a fresh baseline to compare against
  microbenchmarks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run microbenchmark
        run: cargo bench -- --output-format bencher | tee output.txt

      - name: Download nightly microbenchmark data
        uses: actions/cache/restore@v4
        with:
          path: ./microbenchmarks-cache
          key: ${{ runner.os }}-microbenchmarks

      - name: Update microbenchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: cargo bench
          tool: 'cargo'
          output-file-path: output.txt
          github-token: ${{ secrets.GITHUB_TOKEN }}
          external-data-json-path: ./microbenchmarks-cache/benchmark-data.json
          fail-on-alert: true
          summary-always: true
          max-items-in-chart: 30

      - name: Save nightly microbenchmark data
        uses: actions/cache/save@v4
        with:
          path: ./microbenchmarks-cache
          key: ${{ runner.os }}-microbenchmarks

  benchmarks:
    runs-on: warp-ubuntu-latest-x64-16x
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y traceroute
          sudo snap install aws-cli --classic

      - name: System information
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.TIGRIS_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.TIGRIS_AWS_SECRET_ACCESS_KEY }}
          AWS_BUCKET: ${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}
          AWS_REGION: auto
          AWS_ENDPOINT: https://t3.storage.dev
        run: |
          echo "=== CPU ==="
          lscpu
          echo -e "\n=== Memory ==="
          free -h
          echo -e "\n=== Disk Space ==="
          df -h
          echo -e "\n=== Workspace Directory ==="
          du -sh ${{ github.workspace }}
          echo -e "\n=== Network ==="
          traceroute t3.storage.dev
          echo -e "Generating 1 gig file"
          dd if=/dev/urandom of=/tmp/1gig bs=1G count=1
          echo -e "Uploading 1 gig file"
          time aws s3 cp --endpoint-url $AWS_ENDPOINT /tmp/1gig s3://${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}/1gig
          echo -e "Downloading 1 gig file"
          time aws s3 cp --endpoint-url $AWS_ENDPOINT s3://${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}/1gig /tmp/1gig
          echo -e "Deleting 1 gig file"
          time aws s3 rm --endpoint-url $AWS_ENDPOINT s3://${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}/1gig

      - name: Run benchmark
        env:
          CLOUD_PROVIDER: aws
          AWS_ACCESS_KEY_ID: ${{ secrets.TIGRIS_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.TIGRIS_AWS_SECRET_ACCESS_KEY }}
          AWS_BUCKET: ${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}
          AWS_REGION: auto
          AWS_ENDPOINT: https://t3.storage.dev
          SLATEDB_BENCH_CLEAN: true
        run: |
          aws s3 rm --endpoint-url $AWS_ENDPOINT s3://${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }} --recursive
          ./slatedb-bencher/benchmark-db.sh

      - name: Update benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: slatedb-bencher/benchmark-db.sh
          tool: 'customBiggerIsBetter'
          output-file-path: target/bencher/results/benchmark-data.json
          github-token: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}
          fail-on-alert: true
          summary-always: true
          max-items-in-chart: 30
          auto-push: true
          gh-repository: github.com/slatedb/slatedb-website
          benchmark-data-dir-path: performance/benchmarks/main

  microbenchmark-pprofs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y linux-tools-common linux-tools-generic linux-tools-`uname -r`

      - name: Configure perf
        run: |
          echo -1 | sudo tee /proc/sys/kernel/perf_event_paranoid
          echo 0 | sudo tee /proc/sys/kernel/kptr_restrict

      - name: Generate pprofs
        env:
          CARGO_PROFILE_BENCH_DEBUG: true
          SLATE_BENCH_PROFILE: true
        run: |
          # Get list of benchmarks
          BENCHMARKS=$(cargo bench --no-run --message-format=json | jq -r 'select(.profile.test == true and (.target.kind | contains(["bench"]))) | .target.name' | sort -u)

          # Create pprofs for each benchmark
          for bench in $BENCHMARKS; do
            cargo bench --bench $bench -- --profile-time 10
          done

      - name: Checkout website repository
        uses: actions/checkout@v4
        with:
          repository: slatedb/slatedb-website
          token: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}
          path: slatedb-website
          ref: gh-pages

      - name: Update website with new pprofs
        env:
          PPROF_WEBSITE_DIR: performance/microbenchmark-pprofs/main
        run: |
          cd slatedb-website
          git config --global user.name 'github-actions[bot]'
          git config --global user.email '41898282+github-actions[bot]@users.noreply.github.com'
          # Remove old .pb files
          rm -f $PPROF_WEBSITE_DIR/*.pb
          # Copy pprof to $PPROF_WEBSITE_DIR/<benchmark_name>.pb
          find ../target/criterion -name "profile.pb" -exec sh -c 'cp "$1" "$PPROF_WEBSITE_DIR/$(basename $(dirname $(dirname "$1"))).pb"' sh {} \;
          git add $PPROF_WEBSITE_DIR
          git commit -m "Update microbenchmark pprof for job id ${GITHUB_RUN_ID}"
          git push

  deterministic-simulation-test:
    runs-on: warp-ubuntu-latest-x64-16x
    # Stop running tests at 57m to stay within the 1 hour warp build billing window
    timeout-minutes: 57
    steps:
      - uses: actions/checkout@v4
      - uses: taiki-e/install-action@v2
        with:
          tool: nextest@0.9.98
      - name: Install gdb
        run: |
          sudo apt-get update
          sudo apt-get install -y gdb
      - name: Run DST Tests
        run: cargo nextest run test_dst_nightly -p slatedb-dst --all-features --profile dst-nightly
        env:
          RUSTFLAGS: "--cfg dst --cfg tokio_unstable --cfg slow"

  # This is an integration test that makes sure SlateDB works with ZeroFS.
  # ZeroFS has discovered some issues with SlateDB so we want to make sure
  # we catch them early. Moreover, ZeroFS is an important project in the
  # SlateDB ecosystem, so we want to make sure SlateDB doesn't break it.
  zerofs-kernel-compile-9p:
    name: Compile Linux Kernel on 9P (WAL ${{ matrix.wal_mode }})
    runs-on: ubuntu-latest

    strategy:
      matrix:
        wal_mode: [enabled, disabled]
      fail-fast: false

    env:
      CARGO_INCREMENTAL: 0
      RUSTFLAGS: "-Dwarnings"

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: nightly-2025-04-12
          components: rustfmt, clippy, rust-analyzer

      - name: Start MinIO
        run: |
          docker run -d \
            --name minio \
            -p 9000:9000 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio server /data
          for i in {1..30}; do
            if curl -f http://localhost:9000/minio/health/live; then
              echo "MinIO is ready"
              break
            fi
            sleep 1
          done

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libncurses-dev bison flex libssl-dev libelf-dev bc
          sudo modprobe 9p
          sudo modprobe 9pnet
          sudo modprobe 9pnet_virtio
          lsmod | grep 9p || echo "No 9p modules loaded yet"

      - name: Setup MinIO bucket
        run: |
          wget https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          ./mc alias set myminio http://localhost:9000 minioadmin minioadmin
          ./mc mb myminio/slatedb-test || true

      - name: Clone and configure ZeroFS
        run: |
          # Clone ZeroFS outside of the workspace
          cd /tmp
          git clone https://github.com/Barre/ZeroFS.git zerofs
          cd zerofs
          git checkout bea734e71b788b4ba7ac7ed4cef324aac3fd4470
          # Update ZeroFS Cargo.toml to use local SlateDB with current changes
          if grep -q "slatedb" Cargo.toml; then
            # Always enable wal_disable feature so we can control it at runtime
            sed -i 's|slatedb = .*|slatedb = { path = "'$GITHUB_WORKSPACE'/slatedb", features = ["wal_disable"] }|' Cargo.toml
          fi
          # Add wal_enabled field to slatedb::config::Settings
          echo "Finding all files with slatedb::config::Settings..."
          SETTINGS_FILES=$(grep -r "slatedb::config::Settings {" --include="*.rs" | cut -d: -f1 | sort -u)

          for SETTINGS_FILE in $SETTINGS_FILES; do
            echo "Processing: $SETTINGS_FILE"
            echo "Adding wal_enabled field for mode: ${{ matrix.wal_mode }}"

            # Count occurrences before
            BEFORE_COUNT=$(grep -c "compression_codec: None," "$SETTINGS_FILE" || true)
            echo "Found $BEFORE_COUNT occurrences of compression_codec: None,"

            # Insert wal_enabled field after ALL compression_codec lines
            if [ "${{ matrix.wal_mode }}" = "disabled" ]; then
              # Use perl for more reliable multi-line replacement
              perl -i -pe 's/(compression_codec: None,)/\1\n            wal_enabled: false,/g' "$SETTINGS_FILE"
            else
              perl -i -pe 's/(compression_codec: None,)/\1\n            wal_enabled: true,/g' "$SETTINGS_FILE"
            fi

            # Verify the changes
            AFTER_COUNT=$(grep -c "wal_enabled" "$SETTINGS_FILE" || true)
            echo "Added $AFTER_COUNT wal_enabled fields"
          done
          RUSTFLAGS="-Awarnings" cargo build --profile ci

      - name: Start ZeroFS with 9P support
        run: |
          cd /tmp/zerofs
          mkdir -p /tmp/zerofs-cache
          AWS_ENDPOINT=http://localhost:9000 \
          AWS_ACCESS_KEY_ID=minioadmin \
          AWS_SECRET_ACCESS_KEY=minioadmin \
          AWS_ALLOW_HTTP=true \
          SLATEDB_CACHE_DIR=/tmp/zerofs-cache \
          SLATEDB_CACHE_SIZE_GB=5 \
          ZEROFS_MEMORY_CACHE_SIZE_GB=10 \
          ZEROFS_ENCRYPTION_PASSWORD=secret \
          RUSTFLAGS="-Awarnings" cargo run --profile ci s3://slatedb-test/test &
          echo $! > /tmp/zerofs.pid
          echo "Waiting for ZeroFS 9P server to start..."
          for i in {1..30}; do
            if nc -z 127.0.0.1 5564 2>/dev/null; then
              echo "ZeroFS 9P server is ready"
              break
            fi
            sleep 1
          done
          if ! nc -z 127.0.0.1 5564 2>/dev/null; then
            echo "ZeroFS 9P server failed to start"
            exit 1
          fi

      - name: Mount 9P filesystem
        run: |
          sudo mkdir -p /mnt/zerofs
          sudo mount -t 9p -o trans=tcp,port=5564,version=9p2000.L,msize=1048576,cache=mmap,access=user 127.0.0.1 /mnt/zerofs
          mount | grep zerofs
          touch /mnt/zerofs/test_file && rm /mnt/zerofs/test_file

      - name: Check disk space
        run: df -h

      - name: Download Linux kernel
        run: |
          cd /mnt/zerofs
          wget -q https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.11.tar.xz
          tar -xvf linux-6.11.tar.xz
          rm linux-6.11.tar.xz

      - name: Compile kernel
        run: |
          cd /mnt/zerofs/linux-6.11
          make tinyconfig
          echo "Config size: $(wc -l < .config) lines"
          echo "Starting kernel compilation with $(nproc) cores..."
          time make -j$(nproc) 2>&1 | tee /tmp/kernel-build.log
          if [ -f vmlinux ]; then
            echo "Kernel compilation successful!"
            ls -lh vmlinux
          else
            echo "Kernel compilation failed!"
            exit 1
          fi

      - name: Collect ZeroFS stats
        if: always()
        run: |
          if [ -f /tmp/zerofs.pid ]; then
            PID=$(cat /tmp/zerofs.pid)
            if kill -0 $PID 2>/dev/null; then
              echo "ZeroFS process stats:"
              ps aux | grep $PID | grep -v grep || true
              echo ""
              echo "ZeroFS memory usage:"
              cat /proc/$PID/status | grep -E "Vm|Rss" || true
            fi
          fi

      - name: Cleanup
        if: always()
        run: |
          sudo umount /mnt/zerofs || true
          if [ -f /tmp/zerofs.pid ]; then
            kill $(cat /tmp/zerofs.pid) || true
          fi
          pkill -f "cargo run --profile ci s3://slatedb-test/test" || true
          docker stop minio || true
          docker rm minio || true
