name: Nightly Benchmarks

on:
  schedule:
    # Run at midnight Pacific (8 AM UTC)
    - cron: '0 8 * * *'
  workflow_dispatch:  # Allow manual trigger

permissions:
  # Required for storing benchmark results
  contents: write

jobs:
  # Run and save nightly microbenchmark data so PRs have a fresh baseline to compare against
  microbenchmarks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run microbenchmark
        run: cargo bench -- --output-format bencher | tee output.txt

      - name: Download nightly microbenchmark data
        uses: actions/cache/restore@v4
        with:
          path: ./microbenchmarks-cache
          key: ${{ runner.os }}-microbenchmarks

      - name: Update microbenchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: cargo bench
          tool: 'cargo'
          output-file-path: output.txt
          github-token: ${{ secrets.GITHUB_TOKEN }}
          external-data-json-path: ./microbenchmarks-cache/benchmark-data.json
          fail-on-alert: true
          summary-always: true
          max-items-in-chart: 30

      - name: Save nightly microbenchmark data
        uses: actions/cache/save@v4
        with:
          path: ./microbenchmarks-cache
          key: ${{ runner.os }}-microbenchmarks

  benchmarks:
    runs-on: warp-ubuntu-latest-x64-16x
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y traceroute
          sudo snap install aws-cli --classic

      - name: System information
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.TIGRIS_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.TIGRIS_AWS_SECRET_ACCESS_KEY }}
          AWS_BUCKET: ${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}
          AWS_REGION: auto
          AWS_ENDPOINT: https://t3.storage.dev
        run: |
          echo "=== CPU ==="
          lscpu
          echo -e "\n=== Memory ==="
          free -h
          echo -e "\n=== Disk Space ==="
          df -h
          echo -e "\n=== Workspace Directory ==="
          du -sh ${{ github.workspace }}
          echo -e "\n=== Network ==="
          traceroute t3.storage.dev
          echo -e "Generating 1 gig file"
          dd if=/dev/urandom of=/tmp/1gig bs=1G count=1
          echo -e "Uploading 1 gig file"
          time aws s3 cp --endpoint-url $AWS_ENDPOINT /tmp/1gig s3://${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}/1gig
          echo -e "Downloading 1 gig file"
          time aws s3 cp --endpoint-url $AWS_ENDPOINT s3://${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}/1gig /tmp/1gig
          echo -e "Deleting 1 gig file"
          time aws s3 rm --endpoint-url $AWS_ENDPOINT s3://${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}/1gig

      - name: Download previous mermaid plots
        uses: actions/cache/restore@v4
        with:
          path: ./target/bencher/results/mermaid
          key: ${{ runner.os }}-mermaid-plots

      - name: Run benchmark
        env:
          CLOUD_PROVIDER: aws
          AWS_ACCESS_KEY_ID: ${{ secrets.TIGRIS_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.TIGRIS_AWS_SECRET_ACCESS_KEY }}
          AWS_BUCKET: ${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }}
          AWS_REGION: auto
          AWS_ENDPOINT: https://t3.storage.dev
          SLATEDB_BENCH_CLEAN: true
        run: |
          aws s3 rm --endpoint-url $AWS_ENDPOINT s3://${{ secrets.TIGRIS_AWS_BUCKET_BENCHER }} --recursive
          ./slatedb-bencher/benchmark-db.sh

      - name: Save mermaid plots cache
        uses: actions/cache/save@v4
        with:
          path: ./target/bencher/results/mermaid
          key: ${{ runner.os }}-mermaid-plots

      - name: Add mermaid diagrams to summary
        run: |
          echo "# SlateDB Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Add each mermaid diagram to the summary
          for mermaid_file in target/bencher/results/mermaid/*.mermaid; do
            if [ -f "$mermaid_file" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo '```mermaid' >> $GITHUB_STEP_SUMMARY
              cat "$mermaid_file" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          done

          echo "Mermaid diagrams added to GitHub Actions summary!"
          echo "Total diagrams: $(ls -1 target/bencher/results/mermaid/*.mermaid 2>/dev/null | wc -l)"

  microbenchmark-pprofs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y linux-tools-common linux-tools-generic linux-tools-`uname -r`

      - name: Configure perf
        run: |
          echo -1 | sudo tee /proc/sys/kernel/perf_event_paranoid
          echo 0 | sudo tee /proc/sys/kernel/kptr_restrict

      - name: Generate pprofs
        env:
          CARGO_PROFILE_BENCH_DEBUG: true
          SLATE_BENCH_PROFILE: true
        run: |
          BENCHMARKS=$(cargo bench --no-run --message-format=json | jq -r 'select(.profile.test == true and (.target.kind | contains(["bench"]))) | .target.name' | sort -u)
          for bench in $BENCHMARKS; do
            cargo bench --bench $bench -- --profile-time 10
          done
          find . -name "*.pb" -exec gzip {} \;

      # install instructions from https://github.com/polarsignals/pprofme/tree/main
      - name: Install pprofme
        run: |
          curl -LO https://github.com/polarsignals/pprofme/releases/latest/download/pprofme_$(uname)_$(uname -m)
          curl -sL https://github.com/polarsignals/pprofme/releases/latest/download/pprofme_checksums.txt | shasum --ignore-missing -a 256 --check
          chmod a+x pprofme_$(uname)_$(uname -m)
          sudo mv pprofme_$(uname)_$(uname -m) /usr/local/bin/pprofme

      - name: Upload pprofs and add links to summary
        run: |
          echo "## 🔥 Microbenchmark Performance Profiles" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The following pprof profiles were generated from nightly microbenchmarks:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          PPROF_FILES=$(find . -name "*.pb.gz" -type f 2>/dev/null || true)
          if [ -z "$PPROF_FILES" ]; then
            echo "⚠️ No pprof files found" >> $GITHUB_STEP_SUMMARY
          else
            for pprof_file in $PPROF_FILES; do
              bench_name=$(basename "$pprof_file" .pb.gz)
              description="SlateDB Nightly Microbenchmark: $bench_name ($(date -u +%Y-%m-%d))"
              upload_url=$(pprofme upload -d "$description" "$pprof_file" 2>&1 | grep -o 'https://pprof.me/[a-zA-Z0-9]*' | head -1)
              if [ -n "$upload_url" ]; then
                echo "- [$bench_name]($upload_url)" >> $GITHUB_STEP_SUMMARY
              else
                echo "- ❌ Failed to upload $bench_name" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

  deterministic-simulation-test:
    runs-on: warp-ubuntu-latest-x64-16x
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v4
      - uses: taiki-e/install-action@v2
        with:
          tool: nextest@0.9.98
      - name: Install gdb
        run: |
          sudo apt-get update
          sudo apt-get install -y gdb
      - name: Run DST Tests
        run: cargo nextest run test_dst_nightly -p slatedb-dst --all-features --profile dst-nightly --no-capture
        env:
          RUSTFLAGS: "--cfg dst --cfg tokio_unstable --cfg slow"
          RUST_LOG: "warn"
          SLATEDB_DST_ROOT: "./"

  # This is an integration test that makes sure SlateDB works with ZeroFS.
  # ZeroFS has discovered some issues with SlateDB so we want to make sure
  # we catch them early. Moreover, ZeroFS is an important project in the
  # SlateDB ecosystem, so we want to make sure SlateDB doesn't break it.
  zerofs-kernel-compile-9p:
    name: Compile Linux Kernel on 9P (WAL ${{ matrix.wal_mode }})
    runs-on: ubuntu-latest

    strategy:
      matrix:
        wal_mode: [enabled, disabled]
      fail-fast: false

    env:
      CARGO_INCREMENTAL: 0
      RUSTFLAGS: "-Dwarnings"

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: nightly-2025-04-12
          components: rustfmt, clippy, rust-analyzer

      - name: Start MinIO
        run: |
          docker run -d \
            --name minio \
            -p 9000:9000 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio server /data
          for i in {1..30}; do
            if curl -f http://localhost:9000/minio/health/live; then
              echo "MinIO is ready"
              break
            fi
            sleep 1
          done

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libncurses-dev bison flex libssl-dev libelf-dev bc
          sudo modprobe 9p
          sudo modprobe 9pnet
          sudo modprobe 9pnet_virtio
          lsmod | grep 9p || echo "No 9p modules loaded yet"

      - name: Setup MinIO bucket
        run: |
          wget https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          ./mc alias set myminio http://localhost:9000 minioadmin minioadmin
          ./mc mb myminio/slatedb-test || true

      - name: Find last green SHA on Barre/zerofs main
        id: find
        env:
          GITHUB_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          owner="Barre"
          name="zerofs"
          cursor=null
          while :; do
            resp="$(gh api graphql -f owner="$owner" -f name="$name" -f cursor="$cursor" -f query='
              query($owner:String!, $name:String!, $cursor:String) {
                repository(owner:$owner, name:$name) {
                  ref(qualifiedName: "refs/heads/main") {
                    target { ... on Commit {
                      history(first: 100, after: $cursor) {
                        pageInfo { hasNextPage endCursor }
                        nodes { oid statusCheckRollup { state } }
                      }
                    } }
                  }
                }
              }')"
            sha="$(jq -r '.data.repository.ref.target.history.nodes
                            | map(select(.statusCheckRollup.state=="SUCCESS"))[0].oid // empty' <<<"$resp")"
            if [ -n "${sha:-}" ]; then
              echo "sha=$sha" >> "$GITHUB_OUTPUT"
              break
            fi
            if [ "$(jq -r '.data.repository.ref.target.history.pageInfo.hasNextPage' <<<"$resp")" != "true" ]; then
              echo "No successful commit found on main" >&2
              exit 1
            fi
            cursor="$(jq -r '.data.repository.ref.target.history.pageInfo.endCursor' <<<"$resp")"
          done

      - name: Clone and configure ZeroFS
        run: |
          # Clone ZeroFS outside of the workspace
          cd /tmp
          git clone https://github.com/Barre/ZeroFS.git zerofs
          git checkout ${{ steps.find.outputs.sha }}
          cd zerofs
          # Update ZeroFS Cargo.toml to use local SlateDB with current changes
          if grep -q "slatedb" Cargo.toml; then
            # Always enable wal_disable feature so we can control it at runtime
            sed -i 's|slatedb = .*|slatedb = { path = "'$GITHUB_WORKSPACE'/slatedb", features = ["wal_disable"] }|' Cargo.toml
          fi
          # Add wal_enabled field to slatedb::config::Settings
          echo "Finding all files with slatedb::config::Settings..."
          SETTINGS_FILES=$(grep -r "slatedb::config::Settings {" --include="*.rs" | cut -d: -f1 | sort -u)

          for SETTINGS_FILE in $SETTINGS_FILES; do
            echo "Processing: $SETTINGS_FILE"
            echo "Adding wal_enabled field for mode: ${{ matrix.wal_mode }}"

            # Count occurrences before
            BEFORE_COUNT=$(grep -c "compression_codec: None," "$SETTINGS_FILE" || true)
            echo "Found $BEFORE_COUNT occurrences of compression_codec: None,"

            # Insert wal_enabled field after ALL compression_codec lines
            if [ "${{ matrix.wal_mode }}" = "disabled" ]; then
              # Use perl for more reliable multi-line replacement
              perl -i -pe 's/(compression_codec: None,)/\1\n            wal_enabled: false,/g' "$SETTINGS_FILE"
            else
              perl -i -pe 's/(compression_codec: None,)/\1\n            wal_enabled: true,/g' "$SETTINGS_FILE"
            fi

            # Verify the changes
            AFTER_COUNT=$(grep -c "wal_enabled" "$SETTINGS_FILE" || true)
            echo "Added $AFTER_COUNT wal_enabled fields"
          done
          RUSTFLAGS="-Awarnings" cargo build --profile ci

      - name: Start ZeroFS with 9P support
        run: |
          cd /tmp/zerofs
          mkdir -p /tmp/zerofs-cache
          AWS_ENDPOINT=http://localhost:9000 \
          AWS_ACCESS_KEY_ID=minioadmin \
          AWS_SECRET_ACCESS_KEY=minioadmin \
          AWS_ALLOW_HTTP=true \
          SLATEDB_CACHE_DIR=/tmp/zerofs-cache \
          SLATEDB_CACHE_SIZE_GB=5 \
          ZEROFS_MEMORY_CACHE_SIZE_GB=10 \
          ZEROFS_ENCRYPTION_PASSWORD=secret \
          RUSTFLAGS="-Awarnings" cargo run --profile ci s3://slatedb-test/test &
          echo $! > /tmp/zerofs.pid
          echo "Waiting for ZeroFS 9P server to start..."
          for i in {1..30}; do
            if nc -z 127.0.0.1 5564 2>/dev/null; then
              echo "ZeroFS 9P server is ready"
              break
            fi
            sleep 1
          done
          if ! nc -z 127.0.0.1 5564 2>/dev/null; then
            echo "ZeroFS 9P server failed to start"
            exit 1
          fi

      - name: Mount 9P filesystem
        run: |
          sudo mkdir -p /mnt/zerofs
          sudo mount -t 9p -o trans=tcp,port=5564,version=9p2000.L,msize=1048576,cache=mmap,access=user 127.0.0.1 /mnt/zerofs
          mount | grep zerofs
          touch /mnt/zerofs/test_file && rm /mnt/zerofs/test_file

      - name: Check disk space
        run: df -h

      - name: Download Linux kernel
        run: |
          cd /mnt/zerofs
          wget -q https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.11.tar.xz
          tar -xvf linux-6.11.tar.xz
          rm linux-6.11.tar.xz

      - name: Compile kernel
        run: |
          cd /mnt/zerofs/linux-6.11
          make tinyconfig
          echo "Config size: $(wc -l < .config) lines"
          echo "Starting kernel compilation with $(nproc) cores..."
          time make -j$(nproc) 2>&1 | tee /tmp/kernel-build.log
          if [ -f vmlinux ]; then
            echo "Kernel compilation successful!"
            ls -lh vmlinux
          else
            echo "Kernel compilation failed!"
            exit 1
          fi

      - name: Collect ZeroFS stats
        if: always()
        run: |
          if [ -f /tmp/zerofs.pid ]; then
            PID=$(cat /tmp/zerofs.pid)
            if kill -0 $PID 2>/dev/null; then
              echo "ZeroFS process stats:"
              ps aux | grep $PID | grep -v grep || true
              echo ""
              echo "ZeroFS memory usage:"
              cat /proc/$PID/status | grep -E "Vm|Rss" || true
            fi
          fi

      - name: Cleanup
        if: always()
        run: |
          sudo umount /mnt/zerofs || true
          if [ -f /tmp/zerofs.pid ]; then
            kill $(cat /tmp/zerofs.pid) || true
          fi
          pkill -f "cargo run --profile ci s3://slatedb-test/test" || true
          docker stop minio || true
          docker rm minio || true

  notify:
    # List every top-level job you want to watch
    needs: [microbenchmarks, benchmarks, microbenchmark-pprofs, deterministic-simulation-test, zerofs-kernel-compile-9p]
    if: ${{ always() }}
    permissions:
      issues: write
      contents: read
    runs-on: ubuntu-latest
    steps:
      - name: Comment or open issue if any dependency failed
        if: ${{ contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled') }}
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const runUrl = `${context.serverUrl}/${owner}/${repo}/actions/runs/${context.runId}`;
            const q = `repo:${owner}/${repo} is:issue is:open in:title "Nightly failed"`;
            const found = await github.rest.search.issuesAndPullRequests({ q, per_page: 1 });
            const body = `Another failure.\n\nRun: ${runUrl}`;
            if (found.data.total_count > 0) {
              await github.rest.issues.createComment({
                owner, repo, issue_number: found.data.items[0].number, body
              });
            } else {
              await github.rest.issues.create({
                owner, repo, title: 'Nightly failed', body: `Run: ${runUrl}`,
                labels: ['ci-failure']
              });
            }
